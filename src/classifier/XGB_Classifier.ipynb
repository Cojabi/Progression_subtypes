{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f23ce7",
   "metadata": {},
   "source": [
    "Nested CV XGBoost classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08486e80-0c14-4e07-b7c3-ec1c60bced95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from xgboost import XGBClassifier, DMatrix, plot_importance\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.metrics import auc as aucfunc\n",
    "from copy import deepcopy\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from optuna.trial import Trial\n",
    "from typing import Any, Dict\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b61142-8b5b-47e8-8697-48b8c00130c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###USER INPUT\n",
    "optuna__n_trials = 300\n",
    "optuna__n_jobs = 2\n",
    "nthread = 4\n",
    "k_fold = 8\n",
    "run = \"Name\"\n",
    "if not os.path.isdir(f\"Results_XGB/{run}\"):\n",
    "    os.mkdir(f\"Results_XGB/{run}\")\n",
    "scoring_str = \"AUC_PR\"\n",
    "\n",
    "early_stopping_rounds = 50\n",
    "\n",
    "space = {\"gamma\":optuna.distributions.UniformDistribution(0.1, 6.0),\n",
    "         \"learning_rate\":optuna.distributions.LogUniformDistribution(1e-4, 2),\n",
    "         \"max_depth\":optuna.distributions.IntUniformDistribution(3,12),\n",
    "         \"subsample\":optuna.distributions.DiscreteUniformDistribution(0.6, 1, 0.1)}\n",
    "\n",
    "#### load NACC\n",
    "X_val_full = pd.read_csv(\"\", index_col=0)\n",
    "y_val = pd.read_csv(\"\", index_col=0)\n",
    "y_val = y_val[~y_val.index.duplicated()] -1\n",
    "X_val_full = X_val_full[~X_val_full.index.duplicated()]\n",
    "# Only use NACC pats with labels\n",
    "y_val = X_val_full.join(y_val, on=\"NACCID\", how=\"inner\")[\"0\"].copy()\n",
    "X_val = X_val_full.loc[y_val.index]\n",
    "#exclude MRI\n",
    "#X_val = X_val[X_val.columns[~X_val.columns.str.contains(\"^ST\")]]\n",
    "cols = X_val.columns\n",
    "# add APOE as dummy variables\n",
    "X_val = X_val.join(pd.get_dummies(X_val[\"APOE4\"], prefix=\"APOE\"))\n",
    "X_val.drop(\"APOE4\", axis=1, inplace=True)\n",
    "\n",
    "###### load ADNI data and reduce to cols\n",
    "lables = pd.read_csv(glob.glob(\"\")[0], index_col=0)\n",
    "X_train = pd.read_csv(\"\", index_col=0)\n",
    "X_train = X_train[cols]\n",
    "\n",
    "# add APOE as dummy variables\n",
    "X_train = X_train.join(pd.get_dummies(X_train[\"APOE4\"], prefix=\"APOE\"))\n",
    "X_train.drop(\"APOE4\", axis=1, inplace=True)\n",
    "\n",
    "print(run, \"n_trials:\", optuna__n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec751b7-b41e-43fa-9e73-a9ca98e33acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_val.shape[0] == y_val.shape[0]\n",
    "assert (X_train.columns == X_val.columns).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d59b84-f9e2-4fa3-95d5-0625ffee20b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be7afcc-2ad0-4f3a-a1ba-78aea2e555c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define early stopping for xgb\n",
    "early_stop = EarlyStopping(rounds=early_stopping_rounds, save_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2460f-a026-4b57-b839-8b806719fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions to logg results in optuna study object\n",
    "def store_scores(trial:Trial, scores:dict) -> None:\n",
    "        \"\"\"store scores in trial object, compute mean and std\n",
    "        the array holds the values across folds\"\"\"\n",
    "        \n",
    "        for name, array in scores.items():\n",
    "            \n",
    "            if len(array) > 0:\n",
    "                for i, score in enumerate(array):\n",
    "                    trial.set_user_attr(f\"split{i}_{name}\", score)\n",
    "            \n",
    "            # creates the 'mean_val_score' that will be optimized.\n",
    "            trial.set_user_attr(f\"mean_{name}\", np.nanmean(array))\n",
    "            trial.set_user_attr(f\"std_{name}\", np.nanstd(array))\n",
    "\n",
    "            \n",
    "def store_metrics(trial:Trial, metrics:dict) -> None:\n",
    "    \"\"\"store metrics in trial object, compute mean and std. \n",
    "    the array holds the values across folds\"\"\"\n",
    "\n",
    "    for name, array in metrics.items():\n",
    "        \n",
    "        if len(array) > 0:\n",
    "            for i, metric in enumerate(array):\n",
    "                    trial.set_user_attr(f\"split{i}_{name}\", metric)\n",
    "\n",
    "            trial.set_user_attr(f\"mean_{name}\", np.nanmean(array))\n",
    "            trial.set_user_attr(f\"std_{name}\", np.nanstd(array))\n",
    "\n",
    "            if name in [\"epochs\",\"n_estimators\"]:\n",
    "\n",
    "                trial.set_user_attr(f\"median_{name}\", np.nanmedian(array))\n",
    "                iqr = np.nanquantile(array, 0.75) - np.nanquantile(array,0.25) \n",
    "                trial.set_user_attr(f\"iqr_{name}\", iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a57cc-47f7-4741-baba-27e5f1a3fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aucPR(y_true, y_pred):\n",
    "    \"\"\"Calculate the area under the precision recall curve.\"\"\"\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "    return aucfunc(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958313ae-ef5f-40fe-b984-a031daee9014",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Inner fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66324cd2-e068-485c-8d5f-981e179bd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectiveCV_Gbm(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        param_distributions: dict,\n",
    "        X,\n",
    "        y,\n",
    "        scoring : str = \"AUC\",\n",
    "        cv: int = 5\n",
    "        ) -> None:\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.cv = cv\n",
    "        self.fit_params = None\n",
    "        self.param_distributions = param_distributions\n",
    "        self.scoring = scoring\n",
    "\n",
    "    def __call__(self, trial: Trial) -> float:\n",
    "        \"\"\"callable for optuna search\"\"\"\n",
    "        \n",
    "        fit_params = self._get_params(trial) # sample suggested hyperparams\n",
    "        cv = StratifiedKFold(n_splits = self.cv)\n",
    "        \n",
    "        # containers \n",
    "        metrics = {\n",
    "            \"fit_time\" : [],\n",
    "            \"n_estimators\" : []\n",
    "            }\n",
    "        \n",
    "        scores = {\n",
    "            # train\n",
    "           \"train_AUC\" : [],\n",
    "           \"train_AUC_PR\" : [],\n",
    "           # val\n",
    "           \"val_AUC_PR\" : [],\n",
    "           \"val_AUC\" : []\n",
    "           }\n",
    "        \n",
    "        # get cross-validated estimate for one particular hyperparameter set\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(self.X, self.y)):\n",
    "        \n",
    "            X_train = self.X.iloc[train_idx]\n",
    "            y_train = self.y.iloc[train_idx]\n",
    "            X_val = self.X.iloc[val_idx]    \n",
    "            y_val = self.y.iloc[val_idx]\n",
    "            \n",
    "            # not needed\n",
    "            #dtrain = DMatrix(X_train, label=y_train)\n",
    "            #dtest = DMatrix(X_test, label=y_test)\n",
    "            \n",
    "            # initialize model\n",
    "            estimator = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", \n",
    "                                      nthread=nthread, callbacks=[deepcopy(early_stop)])\n",
    "            estimator.set_params(**fit_params)\n",
    "            \n",
    "            # fit with early stopping on validation set and keep best model\n",
    "            estimator.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            \n",
    "            # predict\n",
    "            y_train_pred = estimator.predict_proba(X_train)[:,1]\n",
    "            y_val_pred = estimator.predict_proba(X_val)[:,1]\n",
    "            \n",
    "            \n",
    "            # evaluate model performance\n",
    "            ## train\n",
    "            AUC_train = roc_auc_score(y_train, y_train_pred)\n",
    "            scores[\"train_AUC\"].append(AUC_train)\n",
    "            scores[\"train_AUC_PR\"].append(calc_aucPR(y_train, y_train_pred))\n",
    "\n",
    "            ## val\n",
    "            AUC_val = roc_auc_score(y_val, y_val_pred)\n",
    "            scores[\"val_AUC\"].append(AUC_val)\n",
    "            scores[\"val_AUC_PR\"].append(calc_aucPR(y_val, y_val_pred))\n",
    "\n",
    "            ## choose scoring to return for optuna to optimize\n",
    "            if self.scoring == \"AUC\":\n",
    "                scores[\"train_score\"] = scores[\"train_AUC\"]\n",
    "                scores[\"val_score\"] = scores[\"val_AUC\"]\n",
    "\n",
    "            elif self.scoring == \"AUC_PR\":\n",
    "                scores[\"train_score\"] = scores[\"train_AUC_PR\"]\n",
    "                scores[\"val_score\"] = scores[\"val_AUC_PR\"]\n",
    "            \n",
    "            # metrics\n",
    "            metrics[\"n_estimators\"].append(estimator.n_estimators)\n",
    "            \n",
    "        # log scores and metrics\n",
    "        store_scores(trial, scores)\n",
    "        store_metrics(trial, metrics)\n",
    "        \n",
    "        return trial.user_attrs[\"mean_val_score\"]\n",
    "    \n",
    "    def _get_params(self, trial: Trial) -> Dict[str, Any]:\n",
    "        \"\"\"estimate/sample fit params using trial history\"\"\"\n",
    "\n",
    "        return {name:trial._suggest(name, distribution) \n",
    "                for name, distribution in self.param_distributions.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f4894d-019e-442c-8a64-003fbc497ecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Outer fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff10b31-bb41-45d3-af2c-e2a45d257ecf",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_estimators = 5024\n",
    "\n",
    "# Nested CV\n",
    "results = []\n",
    "results_pr = []\n",
    "results_train = []\n",
    "results_pr_train = []\n",
    "pr_scores = []\n",
    "pr_scores_train = []\n",
    "cur_fold = 0\n",
    "all_predictions = pd.DataFrame(columns=[\"Score\", \"Fold\"], index=X_train.index)\n",
    "\n",
    "    \n",
    "objective = ObjectiveCV_Gbm(space,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            scoring = scoring_str,\n",
    "                            cv=k_fold,)\n",
    "\n",
    "# create study\n",
    "study = optuna.create_study(study_name='xGBoost',\n",
    "                            storage=f'sqlite:///Results_XGB/{run}/optuna__xgb_{cur_fold}.db', \n",
    "                            direction = \"maximize\", \n",
    "                            load_if_exists = True)\n",
    "\n",
    "# optimize\n",
    "study.optimize(objective, \n",
    "                n_trials = optuna__n_trials,\n",
    "                n_jobs = optuna__n_jobs)\n",
    "\n",
    "#### outer loop predictions\n",
    "best_params = study.best_params\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", \n",
    "                      nthread=nthread, callbacks=[deepcopy(early_stop)])\n",
    "model.set_params(**best_params)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# training score\n",
    "pred_train = model.predict_proba(X_train)[:,1]\n",
    "auc_train = roc_auc_score(y_train, pred_train)\n",
    "results_train.append(auc_train)\n",
    "\n",
    "auc_pr_train = calc_aucPR(y_train, pred_train)\n",
    "results_pr_train.append(auc_pr_train)\n",
    "pr_score_train = average_precision_score(y_train, pred_train)\n",
    "pr_scores_train.append(pr_score_train)\n",
    "\n",
    "# Get feature importance per outer fold\n",
    "pd.DataFrame(model.feature_importances_, index=X_train.columns, \n",
    "             columns=[f\"{run.split('_')[1]}_{cur_fold}\"]).to_csv(f\"Results_XGB/{run}/feat_importance_{cur_fold}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c8053f-1fc2-487e-844e-cb7b51f81824",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b7318-cf54-47ba-8191-993ac8b805e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scores\n",
    "pred = model.predict_proba(X_val)[:,1]\n",
    "auc = roc_auc_score(y_val, pred)\n",
    "results.append(auc)\n",
    "\n",
    "auc_pr = calc_aucPR(y_val, pred)\n",
    "results_pr.append(auc_pr)\n",
    "pr_score = average_precision_score(y_val, pred)\n",
    "pr_scores.append(pr_score)\n",
    "\n",
    "print(f'XGB:   outer_fold:{auc=}, {auc_pr=}, {pr_score=}, hyps:{study.best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cecab-94b2-4d25-91c7-2f6ac3de1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PR curve\n",
    "PrecisionRecallDisplay.from_predictions(y_val, pred, name=\"XGB\")\n",
    "plt.ylim(0, 1)\n",
    "plt.savefig(f\"Results_XGB/{run}/PR_curve.png\", dpi=200)\n",
    "\n",
    "#save results\n",
    "print(f\"{run}. Avg AUC: {np.mean(results)}, {np.std(results)}. Avg PR_score: {np.mean(pr_scores)}, \\\n",
    "     Avg AUC_PR: {np.mean(results_pr)}, {np.std(results_pr)}. \\\n",
    "    \\nTraining performance: {np.mean(results_train)=}, {np.mean(results_pr_train)=}, {np.mean(pr_score_train)=}\")\n",
    "\n",
    "with open(f\"Results_XGB/{run}/results.txt\", \"w\") as f:\n",
    "    f.write(f\"{run}. Avg AUC: {np.mean(results)}, {np.std(results)}. Avg PR_score: {np.mean(pr_scores)}, \\\n",
    "     Avg AUC_PR: {np.mean(results_pr)}, {np.std(results_pr)}. \\\n",
    "    \\nTraining performance: {np.mean(results_train)=}, {np.mean(results_pr_train)=}, {np.mean(pr_score_train)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2795f-5d87-4a1f-a733-f5198d650c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions of current repeat for plotting\n",
    "pred = pd.Series(pred, index=y_val.index)\n",
    "pd.concat([pd.Series(pred), y_val], axis=1).to_csv(f\"Results_XGB/{run}/enrichment.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
